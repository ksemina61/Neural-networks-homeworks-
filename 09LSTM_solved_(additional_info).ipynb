{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W8R8WgZceEk"
      },
      "source": [
        "# Семинар 9: Character-Level LSTM\n",
        "\n",
        "## Вступление\n",
        "На прошлом занятии мы познакомились с тем, как можно векторизовать текстовые данные для решения задач обработки текстов. Сегодня мы продолжим заниматься текстами и посмотрим на простейший пример автоматической генерации текстов при помощи Recurrent Neural Network (RNN).\n",
        "\n",
        "Полезные материалы по RNN можно почитать [здесь](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), а реализацию на PyTorch — [здесь](https://github.com/karpathy/char-rnn).\n",
        "\n",
        "### План семинара\n",
        "1. Подготовка данных\n",
        "2. Имплементация модели\n",
        "3. Обучение модели\n",
        "4. Применение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/hse-ds/iad-deep-learning/blob/master/2023/seminars/09.%20LSTM/09_Character_Level_LSTM_solved.ipynb"
      ],
      "metadata": {
        "id": "N1PAVFEQwWPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning -q"
      ],
      "metadata": {
        "id": "OD5nh3nBPs0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9ada53-b3ff-472a-ab68-2a7b3ba7da7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqUOE2flceEl"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from typing import Iterable, Tuple\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wHfCDyzceEl"
      },
      "source": [
        "## 1. Подготовка данных\n",
        "\n",
        "### Загрузим текст \"Анны Карениной\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/hse-ds/iad-deep-learning/master/2022/seminars/sem09/anna.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OdxVLREPXTa",
        "outputId": "3ce3624c-cee0-4b1b-8b8b-e733c82f89b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-01 17:27:26--  https://raw.githubusercontent.com/hse-ds/iad-deep-learning/master/2022/seminars/sem09/anna.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1985223 (1.9M) [text/plain]\n",
            "Saving to: ‘anna.txt.1’\n",
            "\n",
            "anna.txt.1          100%[===================>]   1.89M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-03-01 17:27:26 (38.5 MB/s) - ‘anna.txt.1’ saved [1985223/1985223]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b34kfqIOceEl",
        "outputId": "2ef82662-067b-4348-cfb5-462c2cff9faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "with open(\"anna.txt\", \"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "text[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В тексте есть пробелы, переносы строки - это важно."
      ],
      "metadata": {
        "id": "ydEHYVWXxcgJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iC21bopceEl"
      },
      "source": [
        "### Токенизируем текст\n",
        "\n",
        "Аналогично предыдущему семинару, в ячейках ниже создадим два словаря для преобразования символов в целые числа и обратно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYVlmnxLceEl",
        "outputId": "a877c62c-d0f1-40ef-bf2f-aff0d70d2814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([44, 27, 23,  0, 70, 24,  5, 17, 16, 33, 33, 33, 35, 23,  0,  0, 54, 17,\n",
              "        25, 23, 57, 74, 64, 74, 24,  8, 17, 23,  5, 24, 17, 23, 64, 64, 17, 23,\n",
              "        64, 74, 39, 24, 47, 17, 24, 58, 24,  5, 54, 17, 55, 11, 27, 23,  0,  0,\n",
              "        54, 17, 25, 23, 57, 74, 64, 54, 17, 74,  8, 17, 55, 11, 27, 23,  0,  0,\n",
              "        54, 17, 74, 11, 17, 74, 70,  8, 17, 56, 26, 11, 33, 26, 23, 54, 82, 33,\n",
              "        33, 62, 58, 24,  5, 54, 70, 27, 74, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "unique_chars = tuple(set(text))\n",
        "int2char = dict(enumerate(unique_chars))\n",
        "char2int = {ch: ii for ii, ch in int2char.items()}\n",
        "\n",
        "# encode the text\n",
        "encoded = torch.tensor([char2int[ch] for ch in text])\n",
        "encoded[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь не важно частота слова, здесь важны буквы, не важен порядок чисел.\n",
        "\n",
        "Первые 100 символов."
      ],
      "metadata": {
        "id": "X-IFh_i1xOpE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azltQy-gceEl"
      },
      "source": [
        "Посмотрим на схему char-RNN:\n",
        "<img src=\"https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/char-rnn/assets/charseq.jpeg?raw=1\" width=\"30%\">\n",
        "\n",
        "Сеть ожидает **one-hot encoded** входа, что означает, что каждый символ преобразуется в целое число (через созданный маппинг), а затем преобразуется в вектор-столбец, где только соответствующий ему целочисленный индекс будет иметь значение 1, а остальная часть вектора будет заполнена нулями. Давайте напишем функцию для этого преобразования.\n",
        "\n",
        "#### Задание: допишите функцию one-hot кодирования последовательности"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В hidden layer у нас LSTM, в предсказаниях - Softmax.\n",
        "\n",
        "LSTM - сохраняет состояние(информацию) из предыдущих слоев. Он долгое время запоминает контекст.\n",
        "\n",
        "Переводим наш текст в вектора, дальше напишем модель и потренируем ее."
      ],
      "metadata": {
        "id": "N3wUc-9ByAFW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnahALhiceEl"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(int_words: torch.Tensor, n_labels: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Creates one-hot representation matrix for a given batch of integer sequences\n",
        "    :param int_words: tensor of ints, which represents current sequence; shape: [batch_size, seq_len]\n",
        "    :param n_labels: vocabulary size (number of unique tokens in data)\n",
        "    :return: one-hot representation of the input tensor; shape: [batch_size, seq_len, n_labels]\n",
        "    \"\"\"\n",
        "    words_one_hot = torch.zeros(\n",
        "        (int_words.numel(), n_labels), dtype=torch.float32, device=int_words.device # формируем вектор: размер словаря умноженное сколько хотим лейблов. Пример хотим 8 лейблов, слов 3 - пространство 3 на 8\n",
        "    ) # первый шаг - создам вектор с ноликами такого размера, второй шаг. Пример: есть сампл с тремя числами [1,3,5]. Длина словаря = 5. Будет три вектора для каждого сэмпла\n",
        "    words_one_hot[torch.arange(words_one_hot.shape[0]), int_words.flatten()] = 1.0\n",
        "    words_one_hot = words_one_hot.reshape((*int_words.shape, n_labels))\n",
        "\n",
        "    return words_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4ZQhskXF4xL",
        "outputId": "ea87e284-cb4c-4d90-ed63-3e282df2bcf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "         [0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 1., 0., 0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "# testing the function\n",
        "test_seq = torch.tensor([[3, 5, 1], [0, 2, 4]]) # хотим вектор длины 8, у нас два семпла, первый семпл - тензор 2 на 2\n",
        "test_one_hot = one_hot_encode(test_seq, 8)\n",
        "\n",
        "print(test_one_hot)\n",
        "# есть индекс 3, у него стоит 1, индекс 5, у него на второй строке тоже 1, индекс 1 на третьей строке тоже 1\n",
        "# 8 - длина словаря"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YyL91CuceEl"
      },
      "source": [
        "### Сформируем батчи\n",
        "На простом примере батчи будут выглядеть так: мы возьмем закодированные символы и разделим их на несколько последовательностей, заданных параметром `batch_size`. Каждая из наших последовательностей будет иметь длину `seq_length`.\n",
        "\n",
        "<img src=\"https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/char-rnn/assets/sequence_batching@1x.png?raw=1\" width=500px>\n",
        "\n",
        "**1. Отбросим часть текста, чтобы у нас были только полные батчи**\n",
        "\n",
        "Каждый батч содержит $N \\times M$ символов, где $N$ — это количество последовательностей в батче (`batch_size`), а $M$ — длина каждой последовательности (`seq_length`). Затем, чтобы получить общее количество батчей $K$, которое мы можем сделать из последовательности, нужно разделить длину последовательности на количество символов в батче. Когда мы узнаем количество батчей, можно получить общее количество символов, которые нужно сохранить, из последовательности: $N \\times M \\times K$.\n",
        "\n",
        "**2. Разделим текст на $N$ частей**\n",
        "\n",
        "Этот шаг нужен, чтобы мы могли проходить по тексту окном размера `[batch_size, seq_len]`. Его можно реализовать при помощи простого `reshape`.\n",
        "\n",
        "**3. Теперь, когда у нас готова матрица текста, мы можем двигаться по ней окном, чтобы получить батчи**\n",
        "\n",
        "Из каждой позиции окна сформируем обучающие пары `(x, y)` следующим образом: $x$ — это все элементы окна кроме последнего столбца, а $y$ — это все элементы окна кроме первого столбца. Тем самым для каждого токена исходного текста мы будем предсказывать следующий за ним токен.\n",
        "\n",
        "#### Задание: допишите функцию генерации батчей"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Простыми словами мы хотим, чтобы у нас модель видела 3 слова до и после, то есть последовательность слов была 3 до и 3 после.\n",
        "\n",
        "Для этого нужно сформировать батчи поэлементно (пример с фильтром).\n",
        "Далее нужно посмотреть, сколько батчей и последновательностей у нас внутри текста.\n",
        "Мы можем узнать, сколько символов нам нужно.\n",
        "\n",
        "То есть нужно поделить текст на батчи, внутри батчей пройтись sequences, набрать сэмплом (x,y)."
      ],
      "metadata": {
        "id": "_soj_Q6_0cbG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ECftYejnvpx"
      },
      "outputs": [],
      "source": [
        "def get_batches(\n",
        "    int_words: torch.Tensor, batch_size: int, seq_length: int\n",
        ") -> Iterable[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Generates batches from encoded sequence.\n",
        "    :param int_words: tensor of ints, which represents the text; shape: [batch_size, -1]\n",
        "    :param batch_size: number of sequences per batch\n",
        "    :param seq_length: number of encoded chars in a sequence\n",
        "    :return: generator of pairs (x, y); x_shape, y_shape: [batch_size, seq_length - 1]\n",
        "    \"\"\"\n",
        "    # 1. Truncate text, so there are only full batches, нужно посчитать количество батчей\n",
        "    window_size = seq_length + 1\n",
        "    batch_size_total = batch_size * window_size # все количество данных для одного батча\n",
        "    n_batches = len(int_words) // batch_size_total # длина всего текста поделить на то, сколько батчей будет\n",
        "    int_words = int_words[: n_batches * batch_size_total] # убираем слова, которые не влезают\n",
        "\n",
        "    # 2. Reshape into batch_size rows\n",
        "    int_words = int_words.reshape((batch_size, -1)) #транспонируем вектора\n",
        "\n",
        "    # 3. Iterate through the text matrix, делим данные на батчи\n",
        "    for position in range(0, int_words.shape[1], window_size):\n",
        "        x = int_words[:, position : position + window_size - 1]\n",
        "        y = int_words[:, position + 1 : position + window_size]\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtKlLXi1ceEl",
        "outputId": "8f719478-9ae9-4380-b06a-dbbb519b5b55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:\n",
            "tensor([[44, 27, 23,  0, 70, 24,  5, 17, 16, 33],\n",
            "        [ 0,  0, 24, 76, 17, 23, 11, 76, 17,  8],\n",
            "        [70, 27, 23, 70, 17, 74, 11,  8, 56, 64],\n",
            "        [24, 26, 17, 70, 27, 56, 55, 48, 27, 70],\n",
            "        [24,  5, 65, 17, 27, 24, 17, 27, 23, 76],\n",
            "        [ 5, 65, 17, 26, 27, 56, 17, 26, 23,  8],\n",
            "        [ 8, 70, 17, 29, 24, 17, 69, 56, 58, 24],\n",
            "        [65, 17, 68, 64, 24,  1, 24, 54, 17, 68]])\n",
            "\n",
            "y:\n",
            "tensor([[27, 23,  0, 70, 24,  5, 17, 16, 33, 33],\n",
            "        [ 0, 24, 76, 17, 23, 11, 76, 17,  8, 27],\n",
            "        [27, 23, 70, 17, 74, 11,  8, 56, 64, 55],\n",
            "        [26, 17, 70, 27, 56, 55, 48, 27, 70, 25],\n",
            "        [ 5, 65, 17, 27, 24, 17, 27, 23, 76, 17],\n",
            "        [65, 17, 26, 27, 56, 17, 26, 23,  8, 17],\n",
            "        [70, 17, 29, 24, 17, 69, 56, 58, 24,  5],\n",
            "        [17, 68, 64, 24,  1, 24, 54, 17, 68, 64]])\n"
          ]
        }
      ],
      "source": [
        "# testing the function\n",
        "test_batches = get_batches(encoded, 8, 50) #encoded - 100 первых слов в тексте анны корениной, размер батча = 8, длина последовательности=50\n",
        "test_x, test_y = next(test_batches)\n",
        "assert test_x.shape == test_y.shape\n",
        "print(f\"x:\\n{test_x[:10, :10]}\\n\")\n",
        "print(f\"y:\\n{test_y[:10, :10]}\")\n",
        "# в y сдвиг на 1 индекс"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeaMa5fKF4xM"
      },
      "source": [
        "### Наконец, подготовим класс датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8P8HmW8F4xM"
      },
      "outputs": [],
      "source": [
        "class AnnaData(torch.utils.data.IterableDataset): # загружаем наш датасет\n",
        "    def __init__(self, int_words: torch.Tensor, batch_size: int, seq_length: int):\n",
        "        self.int_words = int_words # задаем количество слов\n",
        "        self.batch_size = batch_size # размер батча\n",
        "        self.seq_length = seq_length # последовательность\n",
        "\n",
        "    def __iter__(self):\n",
        "        return get_batches(self.int_words, self.batch_size, self.seq_length) # вызываем функцию get_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jouxv0L2ceEl"
      },
      "source": [
        "## 2. Имплементация модели\n",
        "\n",
        "<img src=\"https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/char-rnn/assets/charRNN.png?raw=1\" width=50%>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7s5eRaoceEl"
      },
      "source": [
        "### Структура модели\n",
        "\n",
        "* Создаём и храним необходимые словари.\n",
        "* Определяем слой [LSTM]((https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM)) с помощью инстанса класса `torch.nn.LSTM`, который принимает набор параметров: `input_size` — длина последовательности в батче; `n_hidden` — размер скрытых слоёв; `n_layers` — количество слоёв; `drop_prob` — вероятность дропаута; и `batch_first` — флаг, указывающий на то, что у входных последовательностей размерность батча идёт вдоль нулевой оси.\n",
        "* Определяем слой Dropout с таким же значением `drop_prob`.\n",
        "* Определяем полносвязный слой с набором параметров: размерность ввода — `n_hidden`; размерность выхода — размер словаря.\n",
        "* Наконец, инициализируем веса и начальное скрытое состояние (`self.init_hidden()`)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В модель будет на вход по-одному символ, по этому символу модель должна будет предсказать следующий.\n",
        "\n",
        "Вероятность следующего символа зависит не только от входного. LSTM - хранит контекст на предудущих шагах.\n",
        "\n"
      ],
      "metadata": {
        "id": "pzZCQiFB3LN3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPq1EA38rBqn"
      },
      "outputs": [],
      "source": [
        "class CharRNN(nn.Module): #LSTM уже написанная\n",
        "    def __init__(\n",
        "        self,\n",
        "        unique_tokens: Tuple[str],\n",
        "        n_hidden: int = 256,\n",
        "        n_layers: int = 2,\n",
        "        drop_prob: float = 0.5,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_layers = n_layers\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "        # create mappings, преобразуем наши индексы в символы (предсказываем буквы)\n",
        "        self.unique_tokens = unique_tokens\n",
        "        self.int2char = dict(enumerate(self.unique_tokens))\n",
        "        self.char2int = {ch: ii for ii, ch in self.int2char.items()} # важно делать обратный словарь для читабельности\n",
        "\n",
        "        ## define the LSTM, dropout and fully connected layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            len(self.unique_tokens),\n",
        "            n_hidden,\n",
        "            n_layers,\n",
        "            dropout=drop_prob,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.fc = nn.Linear(n_hidden, len(self.unique_tokens))\n",
        "\n",
        "    def forward(\n",
        "        self, x: torch.Tensor, hidden: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        out = self.dropout(r_output)\n",
        "        # Stack up LSTM outputs using view. You may need to use contiguous to reshape the output.\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        ## Get the output for classification.\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "# инициализаци скрытого слоя\n",
        "    def init_hidden(\n",
        "        self, batch_size: int, weight_device: torch.device\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Creates two new zero tensors for hidden state and cell state of LSTM\n",
        "        :param batch_size: number of sequences per batch\n",
        "        :param weight_device: torch.device(\"cuda\") for GPU init or torch.device(\"cpu\") for CPU init\n",
        "        :return: tuple of two tensors of shape [n_layers x batch_size x n_hidden]\n",
        "        \"\"\"\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (\n",
        "            weight.new(self.n_layers, batch_size, self.n_hidden)\n",
        "            .zero_()\n",
        "            .to(weight_device),\n",
        "            weight.new(self.n_layers, batch_size, self.n_hidden)\n",
        "            .zero_()\n",
        "            .to(weight_device),\n",
        "        )\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om7WKpduF4xN"
      },
      "outputs": [],
      "source": [
        "class CharRNNModule(pl.LightningModule): # тренировка модели\n",
        "    def __init__(\n",
        "        self,\n",
        "        unique_tokens: Tuple[str],\n",
        "        n_hidden: int = 1024,\n",
        "        n_layers: int = 2,\n",
        "        drop_prob: float = 0.5,\n",
        "        batch_size: int = 128, # поделим на данные батчи и пакетами подадим на вход модели\n",
        "        seq_length=256,\n",
        "        lr: float = 0.001,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.model = CharRNN(unique_tokens, n_hidden, n_layers, drop_prob)\n",
        "        self.hidden = None\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "        self.n_chars = len(unique_tokens) # кол-во символов = уникальные токены\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def training_step( # шаг тренировки\n",
        "        self, train_batch: Tuple[torch.Tensor, torch.Tensor]\n",
        "    ) -> torch.Tensor:\n",
        "        x, y = train_batch # подаем на вход тренировачный батч\n",
        "        x, y = x.squeeze(0), y.squeeze(0) # делаем кодирование x,y\n",
        "        x = one_hot_encode(x, self.n_chars)\n",
        "\n",
        "        if self.hidden is None:\n",
        "            self.hidden = self.model.init_hidden(self.batch_size, self.device)\n",
        "        self.hidden = tuple([each.data for each in self.hidden])\n",
        "\n",
        "        output, self.hidden = self.model(x, self.hidden)\n",
        "        loss = self.loss(output, y.reshape(self.batch_size * self.seq_length).long())\n",
        "# обнуление весов\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return self.optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IrBRlEPceEl"
      },
      "source": [
        "## 3. Обучение модели\n",
        "\n",
        "По классике, используем оптимизатор Adam и кросс-энтропию. Но без пары особенностей не обойтись:\n",
        "* Во время цикла будем отделять скрытое состояние от его истории, потому что скрытое состояние LSTM является кортежем скрытых состояний.\n",
        "* Будем использовать gradient clipping, чтобы избавиться от взрывающихся градиентов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "InCNB0ICF4xN",
        "outputId": "4db0b9e0-d0ed-451c-a812-dd602e9ac430",
        "colab": {
          "referenced_widgets": [
            "76218b690f8a481d90339e064a5247a6",
            "2413b1e62047472e9a15d1556aceaaf0",
            "54781df098304b81b0d299c36cdaca36",
            "21e995aff01c4326856b93bc6d2de8eb",
            "5a4e7824d7dd420ca950138e52937e11",
            "cfd2cd524aef440e891f7cd23c7c864b",
            "8466982487644fe19d2fd1d6b8aca840",
            "bbf6d3315273437c834db07eac54e98a",
            "340c8558f908442a90f9cd2780d40e49",
            "9fb0c94c383d43ffa6f4775d3db1cab6",
            "35801db706c54cfdb89c92edbaaa06fe"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type             | Params | Mode \n",
            "---------------------------------------------------\n",
            "0 | model | CharRNN          | 13.0 M | train\n",
            "1 | loss  | CrossEntropyLoss | 0      | train\n",
            "---------------------------------------------------\n",
            "13.0 M    Trainable params\n",
            "0         Non-trainable params\n",
            "13.0 M    Total params\n",
            "52.097    Total estimated model params size (MB)\n",
            "5         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76218b690f8a481d90339e064a5247a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=15` reached.\n"
          ]
        }
      ],
      "source": [
        "# data\n",
        "train_dataset = AnnaData(encoded, batch_size=128, seq_length=256)\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=1,  # batching is already implemented on our side\n",
        "    shuffle=False,\n",
        "    num_workers=1,  # don't change: it will lead to the wrong implementation\n",
        ")\n",
        "# model\n",
        "char_rnn = CharRNNModule(unique_chars, n_hidden=1024, batch_size=128)\n",
        "# trainer\n",
        "trainer = pl.Trainer(max_epochs=15, gradient_clip_val=1.0, accelerator=\"gpu\", devices=1)\n",
        "trainer.fit(char_rnn, train_dataloaders=train_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfZxvNoDceEm"
      },
      "source": [
        "## 4. Применение модели\n",
        "\n",
        "Сперва сохраним обученную модель, чтобы можно было загрузить её позже. В следующей ячейке сохраняются параметры, необходимые для создания той же архитектуры, гиперпараметры скрытого слоя и токены."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем веса: /content/rnn_x_epoch.net\n",
        "\n",
        "Можно открыть только torch, что-то нечитаемое."
      ],
      "metadata": {
        "id": "xJb1m9rt59OV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6RXl5VAceEm"
      },
      "outputs": [],
      "source": [
        "net = char_rnn.model # как выбрать слово или букву, которая будет следующей? (картинка, где нужно выбрать одно число)\n",
        "checkpoint = {\n",
        "    \"n_hidden\": net.n_hidden,\n",
        "    \"n_layers\": net.n_layers,\n",
        "    \"state_dict\": net.state_dict(),\n",
        "    \"tokens\": net.unique_tokens,\n",
        "}\n",
        "\n",
        "with open(\"rnn_x_epoch.net\", \"wb\") as f:\n",
        "    torch.save(checkpoint, f)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2sJhx5iceEm"
      },
      "source": [
        "### Делаем предсказания (Как выбирать следующий символ?)\n",
        "\n",
        "Сгенерируем текст! Для предсказания продолжения текста мы передаём в сеть последний символ, она предсказывает следующий символ, который мы снова передаем на вход, получаем ещё один предсказанный символ и так далее. Наши прогнозы основаны на категориальном распределении вероятностей по всем возможным символам. Мы можем ограничить число символов на каждом шаге генерации, чтобы сделать получаемый предсказанный текст более разумным, рассматривая только некоторые, наиболее вероятные символы. С одной стороны, такой подход позволит нам рассматривать не только самую вероятную последовательность с точки зрения прогноза модели. С другой стороны, мы будем работать с ограниченным набором сгенерированных вариантов, поэтому избавимся от совсем уж шумовых прогнозов. Узнать больше можно [здесь](https://pytorch.org/docs/stable/generated/torch.topk.html#torch.topk)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEIRW_B2ceEm"
      },
      "outputs": [],
      "source": [
        "def predict_next_char(\n",
        "    model: torch.nn.Module, char: str, h: torch.Tensor = None, top_k: int = None\n",
        ") -> Tuple[str, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Given a character and a model, predicts next character in the sequence\n",
        "    :param model: model that outputs next token probability distribution\n",
        "    :param char: last character of the sequence to continue generation from\n",
        "    :param h: hidden state of the model\n",
        "    :param top_k: number of most probable tokens to be chosen from\n",
        "    :return: tuple of next character and new hidden state\n",
        "    \"\"\"\n",
        "    # tensor inputs\n",
        "    x = torch.tensor([[model.char2int[char]]])\n",
        "    x = one_hot_encode(x, len(model.unique_tokens))\n",
        "    x = x.to(device)\n",
        "\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    out, h = model(x, h)\n",
        "\n",
        "    # get the character probabilities\n",
        "    p = torch.nn.functional.softmax(out, dim=1).data.cpu()\n",
        "\n",
        "    # get top characters (выбираем одну вероятность и узнаем индекс - сортируем число)\n",
        "    if top_k is None:\n",
        "        top_ch = torch.arange(len(model.unique_tokens))\n",
        "    else:\n",
        "        p, top_ch = p.topk(top_k)\n",
        "# мы перевели вектор с весами (посчитали веса)\n",
        "    p.squeeze_()\n",
        "    top_ch.squeeze_()\n",
        "    char = top_ch[torch.multinomial(p / p.sum(), 1)]\n",
        "\n",
        "    return model.int2char[char.item()], h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG38j3gQceEm"
      },
      "source": [
        "### Priming и генерирование текста\n",
        "\n",
        "Нужно задать скрытое состояние, чтобы сеть не генерировала произвольные символы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9vpB5gRceEm"
      },
      "outputs": [],
      "source": [
        "def sample(model, size, prime=\"The\", top_k=None):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # run through the prime characters\n",
        "    chars = [ch for ch in prime]\n",
        "    h = model.init_hidden(1, device)\n",
        "    for ch in prime:\n",
        "        char, h = predict_next_char(model, ch, h, top_k=top_k)\n",
        "\n",
        "    chars.append(char)\n",
        "\n",
        "    # pass in the previous character and get a new one\n",
        "    for ii in range(size):\n",
        "        char, h = predict_next_char(model, chars[-1], h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    return \"\".join(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys0joturF4xO",
        "outputId": "0ecc0ba1-5c0b-4814-a621-aa68cd947296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anna;,?!, \n",
            " he had to stain that they were to sen aboniting him and tame talking the chown and\n",
            "any happiness\n",
            "and hus sechant, thaights wish of his find this who had tere all at his hand, too were heard a darent tamily befter the carrea seated and worted the\n",
            "manse and as it importent out and alons, stirn of all the mire, they'rist the man to the did not tell him with with her to so how that the plans than she was the madsely and this talking her husband what he't the werring with all with his\n",
            "first of her. Alexey Alexandrovitch streed to be meaning he was the crows were, and the countest went in the\n",
            "rowing trought to ask\n",
            "her, he was believed the misses, but\n",
            "she had stranged to the sare the parys with strick in\n",
            "the count and antere that the plancial serst and with his\n",
            "stats of was the some, the came,\" and the\n",
            "ridse as he\n",
            "had been a position is a sumperiof wanting to\n",
            "the sorts to that he had train in the camily\n",
            "to all with the stopt was\n",
            "a marred\n",
            "to the stepsed and at overing that he down a sho\n"
          ]
        }
      ],
      "source": [
        "print(sample(net, 1000, prime=\"Anna\", top_k=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В некоторых местах соблюдена грамматика, но есть лексические ошибки, несуществующие слова.\n",
        "\n",
        "Предсказание следующего символа без учета порядка."
      ],
      "metadata": {
        "id": "UWejocH17kEB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "942mjdQHceEm"
      },
      "source": [
        "### Загрузка чекпоинта и генерация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt9ldUuSceEm",
        "scrolled": false,
        "outputId": "6e28b705-7628-4749-a44b-3cb838c96572",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And Levin said to be mentering. The senvest of the some\n",
            "to her away for. His see of the cormorday. He sould her faller at her\n",
            "she was not sometered to\n",
            "saw to him to see, the sace offenent to the\n",
            "strong, and see her hands at one at the from thome to be talking a lently whom he could no take him with a crack and and was the stroagh on her subjection to her hand of a letter trat, and a such a far and was\n",
            "a marry out of the cornors, the\n",
            "shound with the friend with talken to him on the same that the sume one of a senger in still to him, we will see her from this thing in the\n",
            "parss of the point on her find of him and should now think\n",
            "whene an inseared a low, and he could not time that the proming\n",
            "with harss were time to him,\n",
            "with a could not though the compost of a countess he did not belied whom he had been too would all all the\n",
            "seming of\n",
            "the meading,\n",
            "and he had not\n",
            "to stay, but the who would stend her wife, and to begond\n",
            "the true of the plassion of the\n",
            "commors, and him to seak to her and\n",
            "so the sumpres it he well a frown, with when he was so must backity, and the corvorded house on her.\n",
            "\n",
            "\"Ah! I amene the suress and to br our, and the painted with you are she to\n",
            "getting.\"\n",
            "\n",
            "\"Why were you sud how a ceeling were too. Whis, tharous, ald the might of a simurate. They hear to the sare the tood and a since...\" he asked the more of the paserant. He sat a little\n",
            "contessed word on\n",
            "the strong when he had seed the thought of the crosp, at the same, to be all should bouth, will all the plans in the priese, shiling at his wife.\n",
            "\n",
            "The pessination, and his back of that he drived her head him had\n",
            "befone her all the figure with the freshing had barking to the pountious and so to as any\n",
            "thought the sochered, said the consriated would nime to him that\n",
            "he wen the sore of\n",
            "hard the poition. He was all the possibely of his\n",
            "crown and his head, and the corriaghs was not shought of\n",
            "the same trame on him and had, and was not so instant to himself to\n",
            "a solang town on hapbined, a colding the sube oft her\n",
            "was seeming\n"
          ]
        }
      ],
      "source": [
        "with open(\"rnn_x_epoch.net\", \"rb\") as f: # просто выгрузили модель /content/rnn_x_epoch.net\n",
        "    checkpoint = torch.load(f)\n",
        "\n",
        "loaded = CharRNN(\n",
        "    checkpoint[\"tokens\"],\n",
        "    n_hidden=checkpoint[\"n_hidden\"],\n",
        "    n_layers=checkpoint[\"n_layers\"],\n",
        ")\n",
        "loaded.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "# sample using a loaded model\n",
        "print(sample(loaded, 2000, top_k=5, prime=\"And Levin said\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76218b690f8a481d90339e064a5247a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2413b1e62047472e9a15d1556aceaaf0",
              "IPY_MODEL_54781df098304b81b0d299c36cdaca36",
              "IPY_MODEL_21e995aff01c4326856b93bc6d2de8eb"
            ],
            "layout": "IPY_MODEL_5a4e7824d7dd420ca950138e52937e11"
          }
        },
        "2413b1e62047472e9a15d1556aceaaf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfd2cd524aef440e891f7cd23c7c864b",
            "placeholder": "​",
            "style": "IPY_MODEL_8466982487644fe19d2fd1d6b8aca840",
            "value": "Epoch 14: "
          }
        },
        "54781df098304b81b0d299c36cdaca36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf6d3315273437c834db07eac54e98a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_340c8558f908442a90f9cd2780d40e49",
            "value": 1
          }
        },
        "21e995aff01c4326856b93bc6d2de8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fb0c94c383d43ffa6f4775d3db1cab6",
            "placeholder": "​",
            "style": "IPY_MODEL_35801db706c54cfdb89c92edbaaa06fe",
            "value": " 60/? [01:00&lt;00:00,  0.99it/s, v_num=0, train_loss=1.570]"
          }
        },
        "5a4e7824d7dd420ca950138e52937e11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "cfd2cd524aef440e891f7cd23c7c864b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8466982487644fe19d2fd1d6b8aca840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbf6d3315273437c834db07eac54e98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "340c8558f908442a90f9cd2780d40e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fb0c94c383d43ffa6f4775d3db1cab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35801db706c54cfdb89c92edbaaa06fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}